---
layout: post
author: smartsi
title: 深入理解Presto架构
date: 2021-01-23 16:29:01
tags:
  - Presto

categories: Presto
permalink: deep-into-presto-architecture
---

前边的文章，我们简单介绍了[为什么要使用Presto](http://smartsi.club/introducing-presto.html)，[初步安装了Presto](http://smartsi.club/how-install-and-startup-presto.html)。现在我们开始讨论 Presto 的架构。我们深入了解相关的概念，以使你能够了解更多 Presto 的查询执行模型、查询方案规划、基于代价的优化器。

在本文章中，我们首先讨论 Presto 高层次的架构组件。全面了解 Presto 的工作方式这非常重要，尤其是你准备自己安装和维护 Presto 的集群。在本文章的后边部分，当我们探讨 Presto 的查询执行模型时，我们会更加深入了解那些组件。假如你需要诊断和调优慢查询，或者你准备向 Presto 开源项目贡献代码时，了解这些是非常重要的。

## 1. Coordinator和Worker

一般我们第一次安装 Presto 时，只会使用一台机器来运行所有的组件。为了获得所需的可伸缩性和性能，只部署一台是远远不够的。

Presto 是一个分布式SQL查询引擎，类似于大规模并行处理（MPP）样式的数据库和查询引擎。Presto 不仅仅可以实现服务器的垂直扩展，也可以以水平扩展的方式把所有处理分发到服务器集群上。这意味着你可以通过添加更多节点来获得更大的处理能力。

利用这种架构，Presto 查询引擎能够跨机器集群或节点并行处理大规模的 SQL 查询。Presto 在每个节点上都是单进程的服务。运行 Presto 的多个节点（配置为彼此协作）组成一个 Presto 集群。

下图展示了由一个 Coordinator 和多个 Worker 节点组成的 Presto 集群。Presto 用户通过客户端连接到 Coordinator，例如，使用 JDBC 驱动程序或 Presto CLI。然后，Coordinator 与 Worker 节点协作，Worker 节点来访问数据源。

![](1)

Coordinator 专门用来处理用户的查询请求以及管理 Worker 节点以执行查询。Worker 节点则负责执行任务和处理数据。Discovery 服务通常运行在 Coordinator 节点上，可以让 Worker 节点注册添加到集群上。客户端、Coordinator，Worker 节点之间的所有通信以及数据传输都是基于 REST 的 HTTP/HTTPS 协议交互。

下图展示了集群内 Coordinator 和 Worker 之间以及 Worker 和 Worker 之间是如何通信的。Coordinator 与多个 Worker 通信，用于分配任务，更新状态以及获得最终的结果集返回给用户。Worker 之间可以相互通信，从运行在其他 Worker 节点的上游任务获取数据。所有 Worker 都可以从数据源读取数据。

![](2)

## 2. Coordinator

Coordinator 主要负责接收 Presto 用户的 SQL 语句，并解析这些 SQL 语句，然后生成查询计划以及管理 Worker 节点。Coordinator 是 Presto 集群的大脑，并且负责与客户端交互。用户可以通过 Presto CLI、使用 JDBC，ODBC 驱动的应用程序以及其他不同语言的客户端库与 Coordinator 进行交互。Coordinator 从客户端接收 SQL 语句才能进行计算，例如 select 语句。

每个 Presto 集群必须有一个 Coordinator，至少一个 Worker。在开发和测试环境中，一个 Presto 进程可以同时配置成这两种角色。Coordinator 追踪每个 Worker 的活跃状态，并且配合查询的执行。Coordinator 会为查询创建一个包含多个 Stage 的逻辑模型。下图展示了客户端、Coordinator 以及 Worker 之间的通信。

![](3)

收到 SQL 语句后，Coordinator 就会负责解析、分析、生成查询计划以及在不同 Worker 节点上调度查询的执行。SQL 语句会被翻译为一系列相关联的 Task，并运行在不同 Worker 节点上。Worker 一边处理数据，Coordinator 一边拉取结果，放在输出缓冲区并展示给客户端。一旦客户端读完输出缓冲区中的数据，Coordinator 便代表客户端向 Worker 请求更多的数据。反过来，Worker 与数据源交互以从中获取数据。因此，客户端连续请求数据，并由 Worker 从数据源提供数据，直到查询执行完成。Coordinator 通过基于 HTTP 的协议与 Worker 和客户端进行通信。

## 3. Discovery Service（发现服务）

Presto 使用发现服务来查找集群中的所有节点。每个 Presto 实例在启动时都会向发现服务注册，并定期发送心跳信号。这可以让 Coordinator 获得最新的可用 Worker 节点列表，并且使用这个列表来调度查询的执行。如果一个 Worker 没有发送心跳信号，发现服务触发故障检测，这一个 Worker 就不会调度到新的任务了。为了简化部署，避免运行额外的服务，Coordinator 通常会运行一个嵌入式的发现服务。会与 Presto 共享一个 HTTP 服务，并使用同一个端口。发现服务 Worker 节点上的配置，通常指向 Coordinator 的主机名称与端口。

## 4. Workers

Presto 的 Worker 是 Presto 集群中的一个服务。它负责运行 Coordinator 分配给它的任务以及数据的处理。Worker 节点通过 Connectors 向数据源获取数据，并且相互之间可以交换中间数据。最终结果会传递给 Coordinator。Coordinator 负责从 Worker 中获取最终结果，并传递给客户端。

在安装过程中，要把发现服务的主机名或IP地址告诉 Worker。当 Worker 启动后，会向发现服务广播自己，之后 Coordinator 才能为其分配任务。Worker 与其他 Worker 以及与 Coordinator 之间的通信都采用基于 HTTP 的协议。

下图显示了多个 Worker 如何从数据源获取数据，并协作处理数据，直到有一个 Worker 把数据提供给了 Coordinator。

![](4)

## 5. 基于Connector的架构

Presto 中存储与计算分离的核心是基于 Connector 的架构。Connector 为 Presto 提供了一个可以访问任意数据源的接口。

每个 Connector 为底层的数据源提供了一层基于表的抽象接口。只要数据能够表示为表、列、行，并且可以使用 Presto 支持的数据类型，那么就可以创建一个 Connector，查询引擎就可以通过这个 Connector 处理数据。

Presto 提供了一套 SPI 接口，可以使用它们来实现 Connector。通过实现 SPI 接口，Presto 就可以在内部使用标准的操作连接任何数据源，并且在数据源上执行任何操作。Connector 负责和数据源交互的细节。

每个 Connector 都要实现 API 的三个部分：
- 读取 table/view/schema 元数据的操作。
- 提供逻辑上的数据分区，这样 Presto 就可以并行读写。
- 用于将源数据转换为查询引擎期望的内存格式的数据源（Data Source）以及将内存格式转换为源数据的Sink。

Presto 为很多系统都提供了 Connector，例如，HDFS/Hive、MySQL、PostgreSQL、MS SQL Server、Kafka、Cassandra、Redis等等。

另外，Presto 的 SPI 接口还可以为我们提供创建自定义 Connector 的能力。这在你访问的数据源没有兼容的 Connector 场景下是非常重要的。如果您的企业中有专有的数据源（非开源），这就可能需要自定义 Connector。这就是 Presto 用户可以使用 SQL 来查询任何数据源的真正原因了。

下图展示了 Presto SPI 为 Coordinator 使用的元数据，数据统计，数据位置 以及 Worker 使用的数据流提供的不同接口。

![](5)

Presto Connector 是每个服务在启动时都要加载的插件。可以通过 catalog 属性文件中特定参数进行配置，并且会从 plugin 目录加载。

## 6. Catalogs, Schemas, 以及 Tables

Presto 集群使用前面描述的基于 Connector 的架构来处理所有查询。每个 catalog 配置都会使用一个 Connector 来访问指定的数据源。数据源在 catalog 中展示一个或多个 schemas。每个 schema 包含若干个 table，table 中的每一行就是多列数据，每一列是不同的类型。

## 7. 查询执行模型

假设我们已经了解了 Presto 如何部署包含一个 Coordinator和多个 Worker 的集群，那么我们现在就可以了解 Presto 是如何处理实际的SQL查询语句的。

> 如果不清楚 Presto 的部署，可以参阅[Presto 安装与部署](http://smartsi.club/how-install-and-startup-presto.html)

了解执行模型会有助于对 Presto 性能进行调优。回想一下，Coordinator 使用 CLI 软件（使用 ODBC 或JDBC 驱动程序）或其他客户端的库从终端用户那里接收 SQL 语句。然后 Coordinator 触发所有 Worker 去从数据源中读取数据，生成最终结果集合，并提供给客户端。

首先让我们深入探索一下 Coordinator 内部发生了什么情况。SQL 语句提交给 Coordinator 后，会以文本格式接收。Coordinator 获取该文本后进行解析以及分析。然后，使用 Presto 中的内部数据结构 Query Plan 来为执行创建执行计划，如下图所示。查询计划概括地表示了每个 SQL 语句处理数据并返回结果所需的步骤。

![](6)

如下图所示，查询计划生成过程会使用 Metadata SPI 和 Data Statistics SPI。Coordinator 使用 SPI 来收集有关表的信息以及其他直接连接到数据源的元数据信息。

![](7)

Coordinator 使用 Metadata SPI 获取有关表、列以及数据类类型的信息。这些用来验证查询在语义上是否有效，也会对原始查询中的表达式进行类型检查和安全检查。Data Statistics SPI 用来获取有关行数和表大小的信息，用来在生成查询计划期间执行基于成本的查询优化。然后在创建分布式查询计划阶段使用 Data Location SPI。它用于生成表内容的逻辑拆分（Split）。Split 是工作分配和并行执行的最小单位。

分布式查询计划是简单查询计划的扩展，由一个或多个 Stage 组成。简单查询计划会划分为多个计划段（Plan Fragments）。一个 Stage 描述了一个计划段的运行时，同时它也涵盖了 Stage 计划段描述 Worker 的所有 Task。

Coordinator 会将查询计划进行分解，以允许在集群各个 Worker 上并行执行，从而加快整体查询的速度。如果有多个 Stage，会创建 Stage 依赖树。Stage 的个数取决于查询的复杂性。例如，查询的表，返回的列，JOIN 语句，WHERE 条件，GROUP BY 操作以及其他 SQL 语句都会影响 Stage 的个数。下图显示了如何在集群中的 Coordinator 上将逻辑查询计划转换为分布式查询计划。

![](8)

分布式查询计划定义了 Stage 以及在 Presto 集群上执行查询的方式。Coordinator 使用它来进一步规划以及在所有 Worker 上调度 Task。一个 Stage 会包含一个或多个 Task。通常来说会包含多个 Task，每个 Task 只处理其中一部分数据。如下图所示 Coordinator 将 Stage 的 Task 分配到集群的不同 Worker 节点上：

![](9)

Task 数据处理的单位称为 Split。Split 表示一个 Worker 检索和处理的一片底层数据。Split 是并行和工作分配的最小单位。Connector 对数据执行的特定操作取决于底层数据源。例如，Hive Connector 以指定文件路径、表示需要处理文件的哪一部分的偏移量和长度来描述 Split。

源 Stage 的 Task 以 Page 的形式产生数据，Page 是以列式格式存储的多行数据集合。这些 Page 流向其他中间下游 Stage。不同的 Stage 之间通过 Exchange 算子交换数据，Exchange 会算子从上游的 Stage 中读取数据。

源 Task 使用数据源 SPI 在 Connector 的帮助下从底层数据源获取数据。数据以 Page 的形式展示给 Presto 并流经引擎。算子根据他们的语义来处理和生成 Page。例如，filter 算子会过滤一些行，projection 算子产生有新列的 Page。一个 Task 内部的算子序列成为一个流水线。流水线的最后一个算子会把它输出 Page 放到输出缓存区上。下游 Task 的 Exchange 算子从上游 Task 的缓冲区读取 Page。如下图所示，不同 Worker 上的算子并行执行：

![](10)

Task 创建后，为每个 Split 实例化生成 Driver。Driver 是算子流水线的的一个实例，并处理 Split 中的数据。一个 Task 可以有一个或多个 Driver，具体取决于 Presto 的配置，如下图所示。一旦所有的 Driver 完成数据处理，并将数据传递到下一个 Split，则 Driver 和 Task 的工作就完成了，然后被销毁。

![](11)

算子处理输入数据，并为下游算子产生输出数据。常见的算子包括表扫描、过滤、Join 以及聚合计算等。这一系列算子构成了算子流水线。举个例子，一个流水线可能包含了一个表扫描算子来读取数据，然后过滤数据，最后执行局部聚合。

要处理查询，Coordinator 会使用来自 Connector 的元数据创建一系列的 Split。通过这一系列的 Split，Coordinator 开始在 Worker 上调度 Task 以收集 Split 中的数据。在查询执行期间，Coordinator 将跟踪所有可用的 Split 以及在 Worker 上运行 Task 和处理 Split 的位置。随着 Task 完成处理并产生更多 Split 以进行下游处理，Coordinator 将继续调度 Task，直到没有 Split 需要处理为止。

一旦在 Worker 上的所有的 Split 处理完成，所有的数据都可用，Coordinator 就会把数据结果提供给客户端。

## 8. Query Planning

在深入探讨 Presto 查询计划生成器和基于成本优化工作之前，我们先限定一下我们考虑范围。在这我们提供一个查询示例作为我们探索的背景，以帮助您了解查询计划。如下代码所示，使用 TPC-H 数据集汇总每个国家/地区的所有订单，并展示排名前五的地区：
```sql
SELECT
  (SELECT name FROM region r WHERE regionkey = n.regionkey) AS region_name,
  n.name AS nation_name,
  sum(totalprice) orders_sum
FROM nation n, orders o, customer c
WHERE n.nationkey = c.nationkey
  AND c.custkey = o.custkey
GROUP BY n.nationkey, regionkey, n.name
ORDER BY orders_sum DESC
LIMIT 5;
```
让我们先了一下解查询中SQL的构成以及用途：
- SELECT 查询在 FROM 子句中使用了三个表，隐式的定义了 nation，orders 以及 customer 表之间的 CROSS JOIN
- WHERE 条件从三个表中获取满足条件的行
- 使用 GROUP BY regionkey 进行汇总每个国家/地区的订单值
- 子查询（SELECT name FROM region WHERE regionkey = n.regionkey），用于从区域表中提取区域名称； 请注意，此查询是相关的，就像应该对包含结果集的每一行独立执行一样


一个子查询，SELECT name FROM region WHERE regionkey = n.regionkey向region表中读取region的名称。请注意这个查询是相关联的。

一个oder by语句，按照orders_sum 倒序排序。

limit限制5行，表示返回oders_sum最多的5行返回给用户。



原文:[Presto: The Definitive Guide](https://learning.oreilly.com/library/view/presto-the-definitive/9781492044260/ch01.html#chapter-introduction)
