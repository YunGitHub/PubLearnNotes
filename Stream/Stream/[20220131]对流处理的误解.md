---
layout: post
author: smartsi
title: 对流处理的误解
date: 2022-01-31 10:25:01
tags:
  - Stream

categories: Stream
permalink: stream-processing-myths-debunked
---

我们花了很多时间来思考流处理。更酷的是：我们也花了很多时间帮助其他人思考流处理以及如何使用流应用解决他们的数据问题。这个过程的第一步是纠正对现代流处理的误解（作为一个快速变化的领域，这里有很多误见值得我们思考）。在这篇文章中，我们选择了其中的 6 个进行讲解，由于 Apache Flink 是我们最熟悉的开源流处理框架，所以我们会基于 Flink 来讲解这些例子。
- 误解1：如果不使用批处理就不能使用的流（Lambda架构）
- 误解2：延迟和吞吐量：只能选择一个
- 误解3：微批处理意味着更好的吞吐量
- 误解4：Exactly-Once？完全不可能
- 误解5：流处理只能被应用在'实时'场景里
- 误解6：不管怎么样，流太复杂了

### 1. 误解1：如果不使用批处理就不能使用的流（Lambda架构）

Lambda 架构 在 Apache Storm 和其它流处理项目的早期阶段是一个很有用并且出名的设计模式。这个架构包含了一个快速流层和一个批处理层。

![](1)

之所以使用两层的原因是 Lambda 架构里的流处理只能计算出近似结果（例如，如果发生故障，结果是不可信的），而且只能处理相对少量的事件。虽然这些问题只存在于 Apache Storm 的早期版本中，与现今开源流处理不相关。现今的很多开源流处理框架都具有容错能力，即使出现故障也能产出准确的结果，而且具有高吞吐的计算能力。所以没有必要为了得到'快'而'准确'的结果维护多层架构。现今的流处理器（例如，Flink）可以满足你这两方面的需求。好在人们不再更多地讨论 Lambda 架构，这表明流处理正在走向成熟。

### 2. 误解2：延迟和吞吐量：只能选择一个

早期的开源流处理框架要么是高吞吐，要么是低延迟，因此开源流处理框架不是'海量数据、快速'场景的选择。但是 Flink（可能还有其他流流处理器）同时提供了高吞吐量和低延迟。这里有一个基准测试结果的[示例](https://data-artisans.com/blog/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink)。

让我们从一个基本的角度来研究这一点，特别是从硬件层。让我们考虑一个存在网络瓶颈的流处理 Pipeline（至少我们看到的许多使用 Flink 的 Pipeline 存在这种情况）。在硬件层面，不需要存在这样的权衡。网络容量才是影响最大吞吐量和可达到的最低延迟的主要因素。

一个设计良好的软件系统应可以达到网络上限而不会引入瓶颈问题。虽然 Flink 的性能还是有优化的空间，使其更接近硬件所能达到的水平。但在这一点上，Flink 已经证明可以在 10 节点的集群上每秒处理 1000 万个事件，如果扩展到 1000 个节点，可以同时实现几十毫秒的延迟。根据我们的经验，这种性能水平对于大多数实际部署来说绰绰有余。

### 误解3：微批处理意味着更好的吞吐量

我们可以从另一个角度来讨论性能，不过先让我们来澄清两个容易混淆的概念：
- 微批处理(Micro-batching)：是建立在传统批处理模型之上的数据处理执行和编程模型。通过这项技术，进程或任务可以把一个流当作一系列小型的批次或数据块。
- 缓冲(Buffering)：一种用于访问网络、磁盘、缓存等的优化技术。维基百科中是这样定义的：物理内存里的一块用于临时储存移动数据的区域。

常见的误解是使用微批处理的数据处理框架会比每次处理一个事件的流处理框架有更高的吞吐量，因为微批处理在网络上传输的效率更高。该误解忽略了一个事实，流处理框架不会依赖任何处理和编程模型层面的批处理，但会在物理层面进行缓冲。Flink 确实也会对数据进行缓冲，这也就意味着 Flink 会通过网络一次发送一组处理过的记录，而不是一次只发送一条记录。从性能方面说，不对数据进行缓冲是不可取的，因为通过网络逐个发送记录不会带来任何性能上的好处。所以我们承认，在物理层面根本不存在一次发送一条记录的事情。但缓冲仅用作性能优化。因此，缓冲：
- 对用户是不可见的
- 不应该对系统造成任何影响
- 不应该强加人为的限制
- 不应该限制系统功能

所以对 Flink 的用户来说，他们可以按照单独处理每个记录的方式开发程序，但 Flink 使用缓冲来实现其底层性能优化。事实上，微批处理会以调度任务的形式引入相当大的开销，而如果这样做是为了降低延迟，那么这种开销只会只增不减！流处理器知道该如何利用缓冲的优势而不会带来任务调度方面的开销。

### 4. 误解4：Exactly-Once？完全不可能

这个误解包含了如下几个方面的内容：
- 在现实中 Exactly-once 语义是不可能的
- Exactly-once 语义不可能是端到端的
- Exactly-once 语义从来都不是现实世界的需求
- Exactly-once 语义是以牺牲性能为代价的

之前 Exactly-Once 仅指 Exactly-Once Delivery，而现在这个词被随意用在流处理里，使得这两个词比以前更容易混淆，也失去了它原本的意义。不过，相关概念仍然很重要，因此我们不会完全跳过它。为了尽可能准确，我们将 Exactly-Once 拆分为状态的 Exactly-Once 和传递的 Exactly-Once。

由于之前人们对这两个词的错误使用导致了这两个不同概念的混淆。例如，Apache Storm 使用 At-Least-Once 来描述传递(Storm 不支持状态)，而 Apache Samza 使用 At-Least-Once 来描述应用状态。

状态 Exactly-once 意味着发生故障后，应用程序状态就像没有发生故障一样。例如，我们在维护一个计数器应用程序，在发生故障后，既不会多计数也不能少计数。在这种情况下使用 Exactly-Once 这个词是因为应用程序状态中每条消息都只处理了一次。传递 Exactly-once 意味着发生故障后，接收方（应用程序之外的某个系统）接收到处理后的事件就好像没有发生故障一样。

虽然流处理框架不可能在每个场景中保证传递的 Exactly-once，但可以做到状态的 Exactly-once。Flink 可以做到状态的 Exactly-once，并不会对性能造成显著影响。与 Flink 的 Checkpoint 配合，还能实现 Sink 上的传递 Exactly-once 语义保证。Flink Checkpoint 是应用程序状态的周期性、异步和一致的快照。这就是 Flink 在发生故障时仍然能保证状态 Exactly-once 的原因：Flink 会定时记录（快照）输入流的读取位置和每个算子的相关状态。如果发生故障，Flink 就会回滚到之前的状态，并重新开始计算。

因此，即使重放记录，结果状态中记录也好像只处理了一次。那么端到端的 Exactly-once 处理呢？可以通过让 Checkpoint 兼具事务协调机制来实现，换句话说，就是让 Source 和 Sink 算子参与到 Checkpoint 里来。在框架内部，结果是 Exactly-once 的，从端到端来看，也是 Exactly-once 的，或者说接近一次性。例如，在使用 Kafka 作为 Source，滚动文件(HDFS)作为 Sink 时，从 Kafka 到 HDFS 可以实现端到端的 Exactly-once 处理。类似地，Kafka 作为 Source，Cassandra 作为 Sink 时，如果对 Cassandra 做幂等更新时，那么就可以实现端到端的 Exactly-once 处理。

![](2)

### 5. 误解5：流处理只能被应用在'实时'场景里

这个误解包括如下几个方面的内容：
- 我没有低延迟的应用，所以我不需要流处理器
- 流处理只跟那些持久化之前的过渡数据有关系
- 我们需要批处理器来完成笨重的离线计算

现在是时候思考一下数据集类型与执行模型类型之间的关系了。有两种数据集
- 无限：连续产生的数据，没有终点
- 有限：有限且完整的数据

事实上，许多现实世界的数据集是无限数据集。无论数据存储在 HDFS 上的文件或者目录中，还是存储在 Apache Kafka 等基于日志的系统中，都是如此。有如下示例：
- 用户与移动设备或网站的交互
- 物理传感器提供的测量数据
- 金融市场数据
- 机器日志数据

实际上，在现实世界中很难找到一个有限数据集，不过一个公司的大楼位置信息倒是有限的（不过它也会随着公司业务的增长而变化）。其次，有两种处理模型：
- 流处理：只要有数据生成就会一直处理
- 批处理：在有限的时间内运行完处理，并释放资源

让我们再深入一点，来区分两种没有边界的数据集：连续性流和间歇性流。

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Stream/%E5%AF%B9%E4%BA%8E%E6%B5%81%E5%A4%84%E7%90%86%E6%8A%80%E6%9C%AF%E7%9A%84%E8%B0%AC%E8%A7%81-4.png?raw=true)

使用任意一种模型来处理任意一种数据集是完全可能的，虽然这不是最优的做法。例如，批次处理模型被长时间地应用在无边界的数据集上，特别是间歇性的无边界数据集。现实情况是，大多数批处理任务是通过调度来执行的，每次只处理无边界数据集的一小部分。这意味着流的无边界特质会给某些人带来麻烦（那些工作在流入管道上的人）。

批处理是无状态的，输出只取决于输入。现实情况是，批处理任务会在内部保留状态（比如reducer经常会保留状态），但这些状态只限在批次的边界内，而且它们不会在批次间流窜。当有人尝试实现类似带有"事件时间戳"的时间窗，那么"批次的边界内状态"就会变得很有用，这在处理无边界数据集时是个很常用的手段。处理无边界数据集的批处理器将不可避免地遇到延迟事件(因为上游的延迟)，批次内的数据有可能因此变得不完整。要注意，这里假设我们是基于事件时间戳来移动时间窗的，因为事件时间戳是现实当中最为准确的模型。在执行批处理的时候，迟到的数据会成为问题，即使通过简单的时间窗修复(比如翻转或滑动时间窗)也解决不了这个问题，特别是如果使用会话时间窗，就更难以处理了。因为完成一个计算所需要的数据不会都在一个批次里，所以在使用批次处理无边界数据集时，很难保证结果的正确性。最起码，它需要额外的开销来处理迟到的数据，还要维护批次之间的状态(要等到所有数据达到后才开始处理，或者重新处理批次)。

Flink内建了处理迟到数据的机制，迟到数据被视为真实世界无边界数据的正常现象，所以Flink设计了一个流处理器专门处理迟到数据。有状态的流处理器更适合用来处理无边界数据集，不管数据集是持续生成的还是间歇生成的。使用流处理器只是个锦上添花的事情。

### 6. 缪见6：不管怎么样，流太复杂了

这是最后一个缪见。你也许会想："理论虽好，但我仍然不会采用流技术，因为……"：
- 流框架难以掌握
- 流难以解决时间窗、事件时间戳、触发器的问题
- 流需要结合批次，而我已经知道如何使用批次，那为什么还要使用流？

我们从来没有打算怂恿你使用流，虽然我们觉得流是个很酷的东西。我们相信，是否使用流完全取决于数据和代码的特点。在做决定之前问问自己："我正在跟什么样类型的数据集打交道？"
- 无边界的（用户活动数据、日志、传感器数据）
- 有边界的

然后再问另一个问题："哪部分变化最频繁？"
- 代码比数据变化更频繁
- 数据比代码变化更频繁

对于数据比代码变化更频繁的情况，例如在经常变化的数据集上执行一个相对固定的查询操作，这样会出现流方面的问题。所以，在认定流是一个"复杂"的东西之前，你可能在不知不觉中已经解决过流方面的问题！你可能使用过基于小时的批次任务调度，团队里的其他人可以创建和管理这些批次（在这种情况下，你得到的结果可能是不准确的，而你意识不到这样的结果是批次的时间问题和之前提过的状态问题造成的）。

为了能够提供一组封装了这些时间和状态复杂性的API，Flink社区为此工作了很长时间。在Flink里可以很简单地处理事件时间戳，只要定义一个时间窗口和一个能够抽取时间戳和水印的函数(只在每个流上调用一次)。处理状态也很简单，类似于定义Java变量，再把这些变量注册到Flink。使用Flink的StreamSQL可以在源源不断的流上面运行SQL查询。

最后一点：对代码比数据变化更频繁的情况该怎么办？对于这种情况，我们认为你遇到了探索性问题。使用笔记本或其它类似的工具进行迭代可能适合用来解决探索性问题。在代码稳定了之后，你仍然会碰到流方面的问题。我们建议从一开始就使用长远的方案来解决流方面的问题。

### 7. 流处理的未来

随着流处理的日渐成熟和这些缪见的逐步淡去，我们发现流正朝着除分析应用之外的领域发展。正如我们所讨论的那样，真实世界正连续不断地生成数据。

原文:http://www.infoq.com/cn/news/2016/12/error-stream-proce-eliminate
