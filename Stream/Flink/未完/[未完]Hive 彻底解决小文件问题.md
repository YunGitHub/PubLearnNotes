
最近发现离线任务对一个增量Hive表的查询越来越慢，这引起了我的注意，我在cmd窗口手动执行count操作查询发现，速度确实很慢，才不到五千万的数据，居然需要300s，这显然是有问题的，我推测可能是有小文件。
我去hdfs目录查看了一下该目录：

![](1)

发现确实有很多小文件，有480个小文件，我觉得我找到了问题所在，那么合并一下小文件吧：

这里使用distribute by进行了一个小文件的合并，通过rand() * 5，保证了从map端输出的数据，最多到5个reducer，将小文件数量控制了下来，现在只有3个文件了。

![](2)

合并小文件后，再次做同样的查询，15s就完成了。确实忽略了，增量数据会导致小文件，应该在当初做的时候就做定时的小文件合并，而不是等到现在才发现。

因为这个表每天是有增量数据进去的，增量数据会单独生成一个文件，因为增量数据本身不大，日积月累就形成了大量小文件。不仅对namenode的内存造成压力，对map端的小文件合并也有很大压力。





原文:[彻底解决Hive小文件问题](https://mp.weixin.qq.com/s/V56pPo6LogRMD_CHp9zHGA)
